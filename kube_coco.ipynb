{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cb49210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from PIL import Image\n",
    "from dask.distributed import Client\n",
    "from cerebro.dask_backend import DaskBackend\n",
    "from cerebro.dataset_info import DatasetInfo\n",
    "from cerebro.params import Params\n",
    "from cerebro.etl import etl\n",
    "import cerebro.constants as constants\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d226c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    data = None\n",
    "    with open(\"/data/cerebro_data_storage/coco/annotations/captions_val2014.json\") as f:\n",
    "        data = json.load(f)\n",
    "    dataset = {\n",
    "        'id': [],\n",
    "        'file_name': [],\n",
    "        'height': [],\n",
    "        'width': [],\n",
    "        'captions': [],\n",
    "        'date_captured': [] \n",
    "    }\n",
    "\n",
    "    annotations = {}\n",
    "    annotations_list = data['annotations']\n",
    "    for i in annotations_list:\n",
    "        if not i[\"image_id\"] in annotations:\n",
    "            annotations[i[\"image_id\"]] = []\n",
    "        annotations[i[\"image_id\"]].append(i[\"caption\"])\n",
    "\n",
    "    for i in range(len(data['images'])):\n",
    "        dataset['id'].append(data[\"images\"][i]['id'])\n",
    "        dataset['file_name'].append(data[\"images\"][i]['file_name'])\n",
    "        dataset['height'].append(data[\"images\"][i]['height'])\n",
    "        dataset['width'].append(data[\"images\"][i]['width'])\n",
    "        dataset['captions'].append(annotations[data[\"images\"][i]['id']])\n",
    "        dataset['date_captured'].append(data[\"images\"][i]['date_captured'])\n",
    "\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset.to_csv(\"/data/cerebro_data_storage/coco/annotations/captions_val2014_modified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "772e24c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_preprocessing_routine(row, to_root_path, kwargs):\n",
    "    from torchvision import transforms\n",
    "    input_image_path = to_root_path + str(row[\"file_name\"])\n",
    "    output_caption = row[\"captions\"]\n",
    "    img = Image.open(input_image_path)\n",
    "    img_tensor = transforms.PILToTensor()(img)\n",
    "    enc_model = kwargs['nlp_model']\n",
    "    caption_tensor = enc_model.encode([output_caption], convert_to_tensor=True)\n",
    "    return [img_tensor, caption_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c9eb49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dsk_bknd = DaskBackend(\"0.0.0.0:8786\")\n",
    "\n",
    "    prepare_data()\n",
    "    is_feature_download = [False, True, False, False, False, False]\n",
    "    feature_names = [\"id\", \"file_name\", \"height\", \"width\", \"captions\", \"date_captured\"]\n",
    "    dtypes = (int, str, int, int, list, str)\n",
    "    data_info = DatasetInfo(feature_names, feature_names, [], dtypes, is_feature_download)\n",
    "\n",
    "    metadata_path = \"/data/cerebro_data_storage/coco/annotations/captions_val2014_modified.csv\"\n",
    "    from_root_path = \"/data/cerebro_data_storage/coco/val2014/\"\n",
    "    to_root_path = \"/data/cerebro_data_storage_worker/coco/val2014/\"\n",
    "    output_path = \"\"\n",
    "    requirements_path = \"\"\n",
    "    download_type = constants.DOWNLOAD_FROM_SERVER\n",
    "\n",
    "    nlp_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    params = Params(metadata_path, from_root_path, to_root_path,\n",
    "        output_path, requirements_path, download_type)\n",
    "    \n",
    "    e = etl(dsk_bknd, params, row_preprocessing_routine, data_info)\n",
    "\n",
    "    e.load_data(frac=0.1)\n",
    "    e.shuffle_shard_data()\n",
    "    e.sharded_df.compute()\n",
    "    print(len(e.sharded_df))\n",
    "    result = e.preprocess_data(nlp_model=nlp_model)\n",
    "    print(result.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3bf65b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Client dashboard:  http://0.0.0.0:8787/status\n",
      "Number of workers: 2\n",
      "4050\n",
      "3048     [[[tensor([ 79,  85,  86,  42,  33,  33,  26, ...\n",
      "7454     [[[tensor([ 27,  29,  36,  49,  50,  45,  34, ...\n",
      "3073     [[[tensor([234, 236, 234, 231, 230, 233, 232, ...\n",
      "14425    [[[tensor([109, 109, 109, 109, 109, 108, 105, ...\n",
      "1029     [[[tensor([ 84,  81,  84,  84,  84,  84,  82, ...\n",
      "                               ...                        \n",
      "38198    [[[tensor([153, 155, 126, 139, 237, 205, 195, ...\n",
      "21376    [[[tensor([187, 196, 186, 149, 151, 167, 167, ...\n",
      "39934    [[[tensor([  5,   1,   1,   4,   4,   0,   0, ...\n",
      "23704    [[[tensor([150, 153, 154, 154, 157, 152, 156, ...\n",
      "30478    [[[tensor([255, 255, 255, 255, 255, 255, 255, ...\n",
      "Name: transformed_data, Length: 4050, dtype: object\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a460a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1356a46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
