{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6b0296",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from PIL import Image\n",
    "from dask.distributed import Client\n",
    "from cerebro.dask_backend import DaskBackend\n",
    "from cerebro.dataset_info import DatasetInfo\n",
    "from cerebro.params import Params\n",
    "from cerebro.etl import etl\n",
    "import cerebro.constants as constants\n",
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0cab320",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data():\n",
    "    data = None\n",
    "    with open(\"/data/cerebro_data_storage/coco/annotations/captions_val2014.json\") as f:\n",
    "        data = json.load(f)\n",
    "    dataset = {\n",
    "        'id': [],\n",
    "        'file_name': [],\n",
    "        'height': [],\n",
    "        'width': [],\n",
    "        'captions': [],\n",
    "        'date_captured': [] \n",
    "    }\n",
    "\n",
    "    annotations = {}\n",
    "    annotations_list = data['annotations']\n",
    "    for i in annotations_list:\n",
    "        if not i[\"image_id\"] in annotations:\n",
    "            annotations[i[\"image_id\"]] = []\n",
    "        annotations[i[\"image_id\"]].append(i[\"caption\"])\n",
    "\n",
    "    for i in range(len(data['images'])):\n",
    "        dataset['id'].append(data[\"images\"][i]['id'])\n",
    "        dataset['file_name'].append(data[\"images\"][i]['file_name'])\n",
    "        dataset['height'].append(data[\"images\"][i]['height'])\n",
    "        dataset['width'].append(data[\"images\"][i]['width'])\n",
    "        dataset['captions'].append(annotations[data[\"images\"][i]['id']])\n",
    "        dataset['date_captured'].append(data[\"images\"][i]['date_captured'])\n",
    "\n",
    "    dataset = pd.DataFrame(dataset)\n",
    "    dataset.to_csv(\"/data/cerebro_data_storage/coco/annotations/captions_val2014_modified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8a75f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def row_preprocessing_routine(row, to_root_path, kwargs):\n",
    "    from torchvision import transforms\n",
    "    input_image_path = to_root_path + str(row[\"file_name\"])\n",
    "    output_caption = row[\"captions\"]\n",
    "    img = Image.open(input_image_path)\n",
    "    img_tensor = transforms.PILToTensor()(img)\n",
    "    enc_model = kwargs['nlp_model']\n",
    "    caption_tensor = enc_model.encode([output_caption], convert_to_tensor=True)\n",
    "    return [img_tensor, caption_tensor]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d540384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dsk_bknd = DaskBackend(\"0.0.0.0:8786\")\n",
    "\n",
    "    prepare_data()\n",
    "    is_feature_download = [False, True, False, False, False, False]\n",
    "    feature_names = [\"id\", \"file_name\", \"height\", \"width\", \"captions\", \"date_captured\"]\n",
    "    dtypes = (int, str, int, int, list, str)\n",
    "    data_info = DatasetInfo(feature_names, feature_names, [], dtypes, is_feature_download)\n",
    "\n",
    "    metadata_path = \"/data/cerebro_data_storage/coco/annotations/captions_val2014_modified.csv\"\n",
    "    from_root_path = \"/data/cerebro_data_storage/coco/images/val2014/\"\n",
    "    to_root_path = \"/data/cerebro_data_storage_worker/coco/val2014/\"\n",
    "    output_path = \"\"\n",
    "    requirements_path = \"\"\n",
    "    download_type = constants.DOWNLOAD_FROM_SERVER\n",
    "\n",
    "    nlp_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "    params = Params(metadata_path, from_root_path, to_root_path,\n",
    "        output_path, requirements_path, username, host, pem_path,\n",
    "        download_type)\n",
    "    \n",
    "    e = etl(dsk_bknd, params, row_preprocessing_routine, data_info)\n",
    "\n",
    "    e.load_data(frac=0.1)\n",
    "    e.shuffle_shard_data()\n",
    "    e.sharded_df.compute()\n",
    "    print(len(e.sharded_df))\n",
    "    result = e.preprocess_data(nlp_model=nlp_model)\n",
    "    print(result.compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbb7853",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
